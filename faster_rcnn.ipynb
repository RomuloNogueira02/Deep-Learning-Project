{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\romul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\romul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# load a model pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "# replace the classifier with a new one, that has\n",
    "# num_classes which is user-defined\n",
    "num_classes = 2  # 1 class (person) + background\n",
    "# get number of input features for the classifier\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "# replace the pre-trained head with a new one\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.nn import BCELoss\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCELoss()\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the model to add a different backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poolDatasetV2 import PoolDatasetV2\n",
    "import os\n",
    "import torch\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToImage(),\n",
    "    #v2.RandomHorizontalFlip(p=1),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    #v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224,Â 0.225])\n",
    "])\n",
    "\n",
    "ROOT_DIR = os.getcwd() + \"\\\\dataset\\\\images\"\n",
    "\n",
    "dataset = PoolDatasetV2(ROOT_DIR, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4755 2342\n"
     ]
    }
   ],
   "source": [
    "train, test = dataset.split_Data()\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train[0], train[1]]\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "\n",
    "    max_size_labels = max([len(label) for label in labels])\n",
    "\n",
    "    for label in labels:\n",
    "        if len(label) < max_size_labels:\n",
    "            toadd = torch.Tensor([0.0, 0.0, 0.0, 0.0])\n",
    "            label.extend([toadd for i in range(max_size_labels - len(label))])\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "# collate_fn(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# test_dl = DataLoader(test, batch_size=1171, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (images, labels) in enumerate(train_dl):\n",
    "    print(i, images, labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for images, targets in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch} Loss: {losses}\")\n",
    "\n",
    "    model.eval()\n",
    "    for images, targets in test_dl:\n",
    "        with torch.no_grad():\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "    print(f\"Epoch {epoch} Loss: {losses}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence #(1)\n",
    "\n",
    "def custom_collate(data): #(2)\n",
    "    inputs = [torch.tensor(d['tokenized_input']) for d in data] #(3)\n",
    "    labels = [d['label'] for d in data]\n",
    "\n",
    "    inputs = pad_sequence(inputs, batch_first=True) #(4)\n",
    "    labels = torch.tensor(labels) #(5)\n",
    "\n",
    "    return { #(6)\n",
    "        'tokenized_input': inputs,\n",
    "        'label': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[[0.5608, 0.5412, 0.5333,  ..., 0.3059, 0.2980, 0.2471],\n",
       "           [0.6000, 0.5529, 0.5373,  ..., 0.2667, 0.2706, 0.2667],\n",
       "           [0.4706, 0.5098, 0.5020,  ..., 0.2549, 0.2667, 0.2510],\n",
       "           ...,\n",
       "           [0.3608, 0.3804, 0.3804,  ..., 0.5451, 0.5255, 0.5059],\n",
       "           [0.3686, 0.3608, 0.3608,  ..., 0.5451, 0.5294, 0.5216],\n",
       "           [0.4000, 0.4118, 0.4235,  ..., 0.5490, 0.5333, 0.5333]],\n",
       "  \n",
       "          [[0.5294, 0.5294, 0.5137,  ..., 0.4275, 0.4078, 0.3569],\n",
       "           [0.5804, 0.5412, 0.5176,  ..., 0.3725, 0.3804, 0.3725],\n",
       "           [0.4745, 0.5020, 0.4824,  ..., 0.3569, 0.3686, 0.3569],\n",
       "           ...,\n",
       "           [0.4510, 0.4784, 0.4824,  ..., 0.5451, 0.5176, 0.4863],\n",
       "           [0.4510, 0.4510, 0.4471,  ..., 0.5412, 0.5176, 0.5020],\n",
       "           [0.4745, 0.4863, 0.4941,  ..., 0.5412, 0.5216, 0.5137]],\n",
       "  \n",
       "          [[0.5059, 0.4824, 0.4471,  ..., 0.3255, 0.3098, 0.2588],\n",
       "           [0.5608, 0.5059, 0.4706,  ..., 0.2745, 0.2824, 0.2784],\n",
       "           [0.4314, 0.4667, 0.4510,  ..., 0.2706, 0.2745, 0.2627],\n",
       "           ...,\n",
       "           [0.3059, 0.3333, 0.3412,  ..., 0.4980, 0.4431, 0.4078],\n",
       "           [0.3137, 0.3137, 0.3255,  ..., 0.5020, 0.4510, 0.4314],\n",
       "           [0.3529, 0.3647, 0.3922,  ..., 0.5098, 0.4549, 0.4471]]]),\n",
       "  [tensor([ 40.6875, 105.8750,  52.0625, 116.8125]),\n",
       "   tensor([ 15.7500,  98.0000,  29.3125, 108.5000])]),\n",
       " (tensor([[[0.2039, 0.2471, 0.2549,  ..., 0.7059, 0.7098, 0.6627],\n",
       "           [0.2824, 0.2549, 0.2314,  ..., 0.6157, 0.6235, 0.7020],\n",
       "           [0.4392, 0.3137, 0.2157,  ..., 0.6000, 0.6392, 0.7725],\n",
       "           ...,\n",
       "           [0.1098, 0.0784, 0.0824,  ..., 0.6510, 0.6588, 0.7961],\n",
       "           [0.1098, 0.0784, 0.0784,  ..., 0.6549, 0.6549, 0.7961],\n",
       "           [0.1216, 0.0824, 0.0784,  ..., 0.7333, 0.7176, 0.7843]],\n",
       "  \n",
       "          [[0.2039, 0.2471, 0.2549,  ..., 0.6039, 0.6157, 0.5686],\n",
       "           [0.2824, 0.2549, 0.2314,  ..., 0.5059, 0.5137, 0.5922],\n",
       "           [0.4314, 0.3059, 0.2078,  ..., 0.4549, 0.4941, 0.6353],\n",
       "           ...,\n",
       "           [0.1451, 0.1137, 0.1255,  ..., 0.5294, 0.5451, 0.6824],\n",
       "           [0.1451, 0.1137, 0.1216,  ..., 0.5333, 0.5412, 0.6824],\n",
       "           [0.1569, 0.1176, 0.1216,  ..., 0.6118, 0.6039, 0.6706]],\n",
       "  \n",
       "          [[0.1647, 0.2078, 0.2157,  ..., 0.5059, 0.5216, 0.4745],\n",
       "           [0.2431, 0.2157, 0.1922,  ..., 0.4118, 0.4275, 0.5059],\n",
       "           [0.3843, 0.2588, 0.1608,  ..., 0.3804, 0.4196, 0.5569],\n",
       "           ...,\n",
       "           [0.1725, 0.1412, 0.1490,  ..., 0.4588, 0.4745, 0.6118],\n",
       "           [0.1725, 0.1412, 0.1451,  ..., 0.4627, 0.4706, 0.6118],\n",
       "           [0.1843, 0.1451, 0.1451,  ..., 0.5412, 0.5333, 0.6000]]]),\n",
       "  [tensor([0., 0., 0., 0.])])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values are token indices but it does not matter - it can be any kind of variable-size data\n",
    "nlp_data = [\n",
    "    {'tokenized_input': [1, 4, 5, 9, 3, 2],\n",
    "     'label':0},\n",
    "    {'tokenized_input': [1, 7, 3, 14, 48, 7, 23, 154, 2],\n",
    "     'label':0},\n",
    "    {'tokenized_input': [1, 30, 67, 117, 21, 15, 2],\n",
    "     'label':1},\n",
    "    {'tokenized_input': [1, 17, 2],\n",
    "     'label':0},\n",
    "]\n",
    "loader = DataLoader(nlp_data, batch_size=2, shuffle=False, collate_fn=custom_collate)\n",
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokenized_input': tensor([[  1,   4,   5,   9,   3,   2,   0,   0,   0],\n",
       "         [  1,   7,   3,  14,  48,   7,  23, 154,   2]]),\n",
       " 'label': tensor([0, 0])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
